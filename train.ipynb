{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!cd data\n",
    "!wget -r -N -c -np https://physionet.org/files/mitdb/1.0.0/\n",
    "!wget -r -N -c -np https://physionet.org/files/nstdb/1.0.0/\n",
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import wfdb\n",
    "\n",
    "from models import FCN_DAE\n",
    "\n",
    "torch.random.manual_seed(2024)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# check and select device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw, _ = wfdb.rdsamp(\"./data/physionet.org/files/nstdb/1.0.0/bw\", channels=[0])\n",
    "em, _ = wfdb.rdsamp(\"./data/physionet.org/files/nstdb/1.0.0/em\", channels=[0])\n",
    "ma, _ = wfdb.rdsamp(\"./data/physionet.org/files/nstdb/1.0.0/ma\", channels=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(signal, noise_type, snr, train=True):\n",
    "    assert noise_type in [\"bw\", \"em\", \"ma\"], \"Noise type must be one of ['bw', 'em', 'ma']\"\n",
    "\n",
    "    st = np.random.randint(0, bw.shape[0]-signal.shape[0]) if train else 0\n",
    "    if noise_type == \"bw\":\n",
    "        noise = bw[st:st+signal.shape[0], 0]\n",
    "    elif noise_type == \"em\":\n",
    "        noise = em[st:st+signal.shape[0], 0]\n",
    "    elif noise_type == \"ma\":\n",
    "        noise = ma[st:st+signal.shape[0], 0]\n",
    "    \n",
    "    # mix signal and noise with SNR\n",
    "    rms_clean = np.sqrt(np.mean(signal**2))\n",
    "    rms_noise = np.sqrt(np.mean(noise**2))\n",
    "    scale = rms_clean / (10**(snr / 20) * rms_noise)\n",
    "    noisy = signal + noise * scale\n",
    "\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitdb_subjects = [s for s in wfdb.io.get_record_list(\"mitdb\") if s not in [\"118\", \"119\"]]\n",
    "val_subjects = np.random.choice(mitdb_subjects, 10) # 10 subjects for validation\n",
    "train_subjects = [s for s in mitdb_subjects if s not in val_subjects]\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.0001\n",
    "epochs = 30\n",
    "\n",
    "# load model\n",
    "model = FCN_DAE().to(DEVICE)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "best_loss = np.inf\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in trange(epochs, desc=\"FCN_DAE Training\"):\n",
    "    # train\n",
    "    model.train()\n",
    "    for t, train_subject in tqdm(enumerate(train_subjects), desc=f\"Train {epoch+1} Epoch\", leave=False):\n",
    "        random_start = np.random.randint(0, 650000 % 1024)  # 650000 is the maximum length of the record, 1024 is the window size\n",
    "        signal, _ = wfdb.rdsamp(f\"./data/physionet.org/files/mitdb/1.0.0/{train_subject}\", channels=[0])   # only use first channel\n",
    "        \n",
    "        train_step_loss = 0\n",
    "        count = 0\n",
    "        for i in tqdm(range(random_start, 650000, 1024), desc=\"Step\", leave=False):\n",
    "            clean_signal = signal[i:i+1024][:, 0]\n",
    "            if clean_signal.shape[0] != 1024:\n",
    "                continue\n",
    "            noisy_signal = add_noise(clean_signal, \"bw\", np.random.randint(-6, 24))\n",
    "\n",
    "            clean_signal = torch.from_numpy(clean_signal.reshape(1, 1, 1024)).to(DEVICE)\n",
    "            noisy_signal = torch.from_numpy(noisy_signal.reshape(1, 1, 1024)).to(DEVICE)\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(noisy_signal.float())\n",
    "            loss = criterion(output, clean_signal.float())\n",
    "            train_step_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        average_step_loss = train_step_loss / count\n",
    "        train_loss.append(average_step_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    current_val_loss = 0\n",
    "    for val_subject in tqdm(val_subjects, desc=f\"Validate {epoch+1} Epoch\", leave=False):\n",
    "        signal, _ = wfdb.rdsamp(f\"./data/physionet.org/files/mitdb/1.0.0/{val_subject}\", channels=[0])   # only use first channel\n",
    "        \n",
    "        val_step_loss = 0\n",
    "        count = 0\n",
    "        for j in tqdm(range(0, 650000, 1024), desc=\"Step\", leave=False):\n",
    "            clean_signal = signal[j:j+1024][:, 0]\n",
    "            if clean_signal.shape[0] != 1024:\n",
    "                continue\n",
    "            noisy_signal = add_noise(clean_signal, \"bw\", -6, train=False)\n",
    "\n",
    "            clean_signal = torch.from_numpy(clean_signal.reshape(1, 1, 1024)).to(DEVICE)\n",
    "            noisy_signal = torch.from_numpy(noisy_signal.reshape(1, 1, 1024)).to(DEVICE)\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "            output, _ = model(noisy_signal.float())\n",
    "            loss = criterion(output, clean_signal.float())\n",
    "            val_step_loss += loss.item()\n",
    "        average_val_loss = val_step_loss / count\n",
    "        val_loss.append(average_val_loss)\n",
    "        current_val_loss += average_val_loss\n",
    "    \n",
    "    if current_val_loss < best_loss:\n",
    "        best_loss = average_val_loss\n",
    "        Path(\"./weights\").mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), f\"./weights/FCN_DAE_lr{str(lr).split('.')[-1]}.pth\")\n",
    "\n",
    "# save loss\n",
    "Path(\"./results/FCN_DAE/\").mkdir(parents=True, exist_ok=True)\n",
    "np.savetxt(\"./results/FCN_DAE/train_loss.txt\", np.array(train_loss), fmt=\"%.4f\")\n",
    "np.savetxt(\"./results/FCN_DAE/val_loss.txt\", np.array(val_loss), fmt=\"%.4f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
